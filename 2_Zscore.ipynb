{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-22T03:39:06.224384Z",
     "start_time": "2018-05-22T03:39:03.237954Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xuhuimin/anaconda3/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from glob import glob\n",
    "import itertools\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import numpy\n",
    "import math\n",
    "import matplotlib.pylab as plt\n",
    "import os\n",
    "import networkx as nx\n",
    "from pypinyin import lazy_pinyin\n",
    "import sys\n",
    "from collections import defaultdict, Counter\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pylab as plt\n",
    "import math\n",
    "#import matplotlib.cm as cm\n",
    "import statsmodels.api as sm\n",
    "from os import listdir\n",
    "from scipy.stats.stats import pearsonr\n",
    "import json\n",
    "import random\n",
    "import itertools\n",
    "from copy import deepcopy\n",
    "import time\n",
    "import scipy as sp\n",
    "from scipy.sparse import csr_matrix\n",
    "import matplotlib.cm as cm\n",
    "from numpy.random import choice\n",
    "import itertools\n",
    "from sklearn import manifold\n",
    "import operator\n",
    "import itertools\n",
    "from datetime import datetime as dt\n",
    "import matplotlib.mlab as mlab\n",
    "from scipy.stats import norm\n",
    "import re\n",
    "from scipy import stats\n",
    "from scipy.spatial import Voronoi\n",
    "from scipy import sparse\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd\n",
    "from pypinyin import lazy_pinyin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose all the users\n",
    "columns = 'user_id，sex，age，occupation_name，education_name，user_opentime，brand_name，call_duration_m，gprs_flow，\\\n",
    "call_fee，gprs_fee，databusiness_fee，order_name，brand_chn，model_chn，screensize，operation_sys，terminal_price，\\\n",
    "dept_county_name，dept_name'.split('，')\n",
    "\n",
    "basename=pd.read_csv('./basename.csv', encoding='gbk', names=columns)\n",
    "\n",
    "users=basename['user_id'].unique()\n",
    "\n",
    "column_list = 'user_id,access_mode_id,logic_area_name,lac,ci,longtitude,latitude,busi_name,busi_type_name,\\\n",
    "app_name,app_type_name,start_time,up_pack,down_pack,up_flow,down_flow,site_name,site_channel,cont_app_id,\\\n",
    "cont_classify_id,cont_type_id,acce_url'.split(',')\n",
    "\n",
    "for user in users:\n",
    "    path='./allusers/'+'user_'+str(user)+'.csv'\n",
    "    #print(path)\n",
    "    if os.path.isfile(path)==True:\n",
    "        \n",
    "        userdata=pd.read_csv(path,names=column_list)\n",
    "        userdata=userdata[['user_id','longtitude','latitude','app_name','app_type_name','start_time']]\n",
    "\n",
    "        with open('./siteexample1/allusers/' + str(user) +'.csv', 'a+') as f:\n",
    "            userdata.to_csv(f,header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-21T04:08:40.073303Z",
     "start_time": "2018-05-21T04:08:39.592437Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xuhuimin/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2698: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# choose the users with high house price & location records>3\n",
    "basename_clean=pd.read_csv('./basename_clean.csv')\n",
    "basename_clean=basename_clean[basename_clean['house_price'].astype('str')!='nan']\n",
    "basename_clean=basename_clean[basename_clean['location']>3]\n",
    "users=basename_clean['user_id'].unique()\n",
    "# print(len(users))\n",
    "column_list = 'user_id,access_mode_id,logic_area_name,lac,ci,longtitude,latitude,busi_name,busi_type_name,\\\n",
    "app_name,app_type_name,start_time,up_pack,down_pack,up_flow,down_flow,site_name,site_channel,cont_app_id,\\\n",
    "cont_classify_id,cont_type_id,acce_url'.split(',')\n",
    "\n",
    "for user in users:\n",
    "    path='./allusers/'+'user_'+str(user)+'.csv'\n",
    "    #print(path)\n",
    "    if os.path.isfile(path)==True:\n",
    "        \n",
    "        userdata=pd.read_csv(path,names=column_list)\n",
    "        userdata=userdata[['user_id','longtitude','latitude','app_name','app_type_name','start_time']]\n",
    "\n",
    "        with open('./siteexample1/allusers/' + str(user) +'.csv', 'a+') as f:\n",
    "            userdata.to_csv(f,header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose the users with terminal price & fees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-22T03:40:34.061982Z",
     "start_time": "2018-05-22T03:40:33.339096Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xuhuimin/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2698: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "basename_clean=pd.read_csv('./basename_clean.csv')\n",
    "basename_clean=basename_clean[(basename_clean['terminal_price'].astype('str')!='nan')&(basename_clean['fees'].astype('str')!='nan')]\n",
    "users=basename_clean['user_id'].unique()\n",
    "# print(len(users))\n",
    "\n",
    "for user in users:\n",
    "    path='./siteexample1/allusers_complete/'+str(user)+'.csv'\n",
    "    #print(path)\n",
    "    if os.path.isfile(path)==True:\n",
    "        \n",
    "        userdata=pd.read_csv(path,names=['user_id','longtitude','latitude','app_name','app_type_name','start_time'])\n",
    "\n",
    "        with open('./siteexample1/allusers/' + str(user) +'.csv', 'a+') as f:\n",
    "            userdata.to_csv(f,header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first put all the unique nodes together, second all pair combinations together,third pair combinations for every user\n",
    "files=glob('./siteexample1/allusers/*')\n",
    "for f in files:\n",
    "    user=f.split('/')[-1].split('.')[0]\n",
    "    userdata=pd.read_csv(f,names=['user_id','longtitude','latitude','app_name','app_type_name','start_time'])\n",
    "    \n",
    "    userdata=userdata[userdata['app_name']!='其他']\n",
    "    userdata=userdata[['user_id','app_name']]\n",
    "    userdata=userdata.drop_duplicates()\n",
    "    \n",
    "#     userdata.to_csv('./siteexample1/node.csv',header=False,mode='a+')\n",
    "    app_list=userdata['app_name'].values\n",
    "    pair=list(itertools.combinations(app_list,2))\n",
    "    data=pd.DataFrame(pair,columns=['node1','node2'])\n",
    "\n",
    "    data['node3']=data['node1'].map(lambda x: ''.join(lazy_pinyin(str(x))))\n",
    "    data['node4']=data['node2'].map(lambda x: ''.join(lazy_pinyin(str(x))))\n",
    "    for i in range(len(data.values)):\n",
    "        if data.values[i][2]>data.values[i][3]:\n",
    "            data.values[i][0],data.values[i][1]=data.values[i][1],data.values[i][0]\n",
    "    \n",
    "    data=data[['node1','node2']]\n",
    "    data.to_csv('./siteexample1/pair.csv',header=False,mode='a+')\n",
    "    \n",
    "    with open('./siteexample1/pair/' + str(user) +'.csv', 'a+') as f:\n",
    "        data.to_csv(f,header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# observed values\n",
    "app_obs=pd.read_csv('./siteexample1/pair.csv',names=['node1','node2'],index_col=0)\n",
    "app_obs['pair']=app_obs['node1'].astype('str')+' '+app_obs['node2'].astype('str')\n",
    "counterdict=Counter(app_obs['pair'].values)\n",
    "counterdict=pd.DataFrame(list(counterdict.items()),columns=['pair','app_obs'])\n",
    "counterdict.to_csv('./siteexample1/observed_value.csv')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "app_df = pd.read_csv('./siteexample1/observed_value.csv', index_col = 0)\n",
    "\n",
    "app_df['node1'] = app_df['pair'].apply(lambda x: x.split(' ')[0])\n",
    "app_df['node2'] = app_df['pair'].apply(lambda x: x.split(' ')[1])\n",
    "\n",
    "app_df = app_df[['node1','node2','app_obs']]\n",
    "\n",
    "\n",
    "From=[]\n",
    "To=[]\n",
    "for ii in app_df.index:\n",
    "    i,j,w= app_df.node1[ii],app_df.node2[ii], app_df.app_obs[ii]\n",
    "    x,y=zip(*[[i,j]]*w)\n",
    "    From+=x\n",
    "    To+=y\n",
    "\n",
    "D=defaultdict(lambda:0)\n",
    "for x,y in zip(From,To):\n",
    "    D[(x,y)]+=1\n",
    "D=dict(D)\n",
    "\n",
    "# expected value\n",
    "DD=defaultdict(lambda:[])\n",
    "for i in range(10):\n",
    "    D1=defaultdict(lambda:0)\n",
    "    To1=np.random.permutation(To)\n",
    "    for x,y in zip(From,To1):\n",
    "        D1[(x,y)]+=1\n",
    "    for x,y in D1:\n",
    "        DD[(x,y)].append(D1[(x,y)])\n",
    "DD=dict(DD)\n",
    "\n",
    "# z score\n",
    "d=[]\n",
    "for x,y in D:\n",
    "    if (x,y) in DD:\n",
    "        m=np.mean(DD[(x,y)]) \n",
    "        sd=np.std(DD[(x,y)])\n",
    "        if sd==0:\n",
    "            sd=1\n",
    "        w=D[(x,y)]\n",
    "        z1=w-m\n",
    "        z=(w-m+0.0)/sd\n",
    "        d.append([x,y,w,z])\n",
    "data = pd.DataFrame(d,columns=['node1','node2','weight','z_score'])\n",
    "data['pair']=data['node1'].astype('str')+' '+data['node2'].astype('str')\n",
    "data.to_csv('./siteexample1/observed_value.csv',header=False,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put z_score into every user-file\n",
    "z_score=pd.read_csv('./siteexample1/observed_value.csv',names=['node1','node2','weight','z_score','pair'])\n",
    "z_score=z_score[['pair','z_score']]\n",
    "diction=dict(z_score.values)\n",
    "\n",
    "files=glob('./siteexample1/pair/*')\n",
    "\n",
    "for f in files:\n",
    "    data=pd.read_csv(f,names=['node1','node2'])\n",
    "    data['pair']=data['node1'].astype('str')+' '+data['node2'].astype('str')\n",
    "    data['z_score']=data['pair'].apply(lambda x: diction[x]\n",
    "                                  if x in diction\n",
    "                                   else np.nan)\n",
    "    data.to_csv(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# four categories group by z_score\n",
    "files=glob('./siteexample1/pair/*')\n",
    "lista=[]\n",
    "listb=[]\n",
    "listc=[]\n",
    "for f in files:\n",
    "    data=pd.read_csv(f)\n",
    "    if len(data['z_score'])>0:\n",
    "        user_id=f.split('/')[-1].split('.')[0]\n",
    "        lista.append(user_id)\n",
    "        list1=list(data[data['z_score'].notnull()]['z_score'].values)\n",
    "        a=numpy.array(list1)\n",
    "        median=numpy.median(a)\n",
    "        listb.append(median)\n",
    "        pertentile_10=numpy.percentile(a,10)\n",
    "        listc.append(pertentile_10)\n",
    "df=pd.DataFrame([lista,listb,listc]).T\n",
    "df.columns=['user_id','median','pertentile_10']\n",
    "df.to_csv('./siteexample1/zscore_category.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add category\n",
    "\n",
    "# df=pd.read_csv('./siteexample1/zscore_category.csv',index_col=0)\n",
    "# df=df[~df.isin([numpy.nan, numpy.inf, -numpy.inf]).any(1)]\n",
    "\n",
    "# high_low=df[(df['median']>df['median'].median())&(df['pertentile_10']>0)].index\n",
    "# df.ix[high_low,'category']='high_low'\n",
    "\n",
    "\n",
    "# low_low=df[(df['median']<=df['median'].median())&(df['pertentile_10']>0)].index\n",
    "# df.ix[low_low,'category']='low_low'\n",
    "\n",
    "# low_high=df[(df['median']<=df['median'].median())&(df['pertentile_10']<=0)].index\n",
    "# df.ix[low_high,'category']='low_high'\n",
    "\n",
    "# high_high=df[(df['median']>df['median'].median())&(df['pertentile_10']<=0)].index\n",
    "# df.ix[high_high,'category']='high_high'\n",
    "\n",
    "# df=df[['user_id','median','pertentile_10','category']]\n",
    "# df.to_csv('./siteexample1/zscore_category.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mobility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first put all the unique nodes together, second all pair combinations together,third pair combinations for every user\n",
    "files=glob('./siteexample1/allusers/*')\n",
    "for f in files:\n",
    "    user=f.split('/')[-1].split('.')[0]\n",
    "    userdata=pd.read_csv(f,names=['user_id','longtitude','latitude','app_name','app_type_name','start_time'])\n",
    "    userdata[userdata['longtitude'].astype('str')!='nan']\n",
    "    userdata=userdata[userdata['latitude'].astype('str')!='nan']\n",
    "    userdata['location']=(userdata['longtitude'].astype('str')+','+userdata['latitude'].astype('str')).values\n",
    "    userdata=userdata[userdata['app_name']!='其他']\n",
    "    userdata=userdata[['user_id','location']]\n",
    "    userdata=userdata.drop_duplicates()\n",
    "    \n",
    "#     userdata.to_csv('./siteexample1/location/node.csv',header=False,mode='a+')\n",
    "    \n",
    "    app_list=userdata['location'].values\n",
    "    pair=list(itertools.combinations(app_list,2))\n",
    "    data=pd.DataFrame(pair)\n",
    "    \n",
    "    for i in range(len(data.values)):\n",
    "        if data.values[i][0].split(',')[0]+data.values[0][0].split(',')[1]>data.values[i][1].split(',')[0]+data.values[0][0].split(',')[1]:\n",
    "            data.values[i][0],data.values[i][1]=data.values[i][1],data.values[i][0]\n",
    "    \n",
    "    data.to_csv('./siteexample1/location/pair.csv',header=False,mode='a+')\n",
    "    \n",
    "    with open('./siteexample1/location/pair/' + str(user) +'.csv', 'a+') as f:\n",
    "        data.to_csv(f,header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# observed values\n",
    "app_obs=pd.read_csv('./siteexample1/location/pair.csv',names=['node1','node2'],index_col=0)\n",
    "app_obs['pair']=app_obs['node1'].astype('str')+' '+app_obs['node2'].astype('str')\n",
    "counterdict=Counter(app_obs['pair'].values)\n",
    "counterdict=pd.DataFrame(list(counterdict.items()),columns=['pair','app_obs'])\n",
    "counterdict.to_csv('./siteexample1/location/observed_value.csv')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_df = pd.read_csv('./siteexample1/location/observed_value.csv', index_col = 0)\n",
    "\n",
    "app_df['node1'] = app_df['pair'].apply(lambda x: x.split(' ')[0])\n",
    "app_df['node2'] = app_df['pair'].apply(lambda x: x.split(' ')[1])\n",
    "\n",
    "app_df = app_df[['node1','node2','app_obs']]\n",
    "\n",
    "\n",
    "From=[]\n",
    "To=[]\n",
    "for ii in app_df.index:\n",
    "    i,j,w= app_df.node1[ii],app_df.node2[ii], app_df.app_obs[ii]\n",
    "    x,y=zip(*[[i,j]]*w)\n",
    "    From+=x\n",
    "    To+=y\n",
    "\n",
    "D=defaultdict(lambda:0)\n",
    "for x,y in zip(From,To):\n",
    "    D[(x,y)]+=1\n",
    "D=dict(D)\n",
    "\n",
    "# expected value\n",
    "DD=defaultdict(lambda:[])\n",
    "for i in range(10):\n",
    "    D1=defaultdict(lambda:0)\n",
    "    To1=np.random.permutation(To)\n",
    "    for x,y in zip(From,To1):\n",
    "        D1[(x,y)]+=1\n",
    "    for x,y in D1:\n",
    "        DD[(x,y)].append(D1[(x,y)])\n",
    "DD=dict(DD)\n",
    "\n",
    "# z score\n",
    "d=[]\n",
    "for x,y in D:\n",
    "    if (x,y) in DD:\n",
    "        m=np.mean(DD[(x,y)]) \n",
    "        sd=np.std(DD[(x,y)])\n",
    "        if sd==0:\n",
    "            sd=1\n",
    "        w=D[(x,y)]\n",
    "        z1=w-m\n",
    "        z=(w-m+0.0)/sd\n",
    "        d.append([x,y,w,z])\n",
    "data = pd.DataFrame(d,columns=['node1','node2','weight','z_score'])\n",
    "data['pair']=data['node1'].astype('str')+' '+data['node2'].astype('str')\n",
    "data.to_csv('./siteexample1/location/observed_value.csv',header=False,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put z_score into every user-file\n",
    "z_score=pd.read_csv('./siteexample1/location/observed_value.csv',names=['node1','node2','weight','z_score','pair'])\n",
    "z_score=z_score[['pair','z_score']]\n",
    "diction=dict(z_score.values)\n",
    "\n",
    "files=glob('./siteexample1/location/pair/*')\n",
    "\n",
    "for f in files:\n",
    "    data=pd.read_csv(f,names=['node1','node2'])\n",
    "    data['pair']=data['node1'].astype('str')+' '+data['node2'].astype('str')\n",
    "    data['z_score']=data['pair'].apply(lambda x: diction[x]\n",
    "                                  if x in diction\n",
    "                                   else np.nan)\n",
    "    data.to_csv(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# four categories group by z_score\n",
    "files=glob('./siteexample1/location/pair/*')\n",
    "lista=[]\n",
    "listb=[]\n",
    "listc=[]\n",
    "for f in files:\n",
    "    data=pd.read_csv(f)\n",
    "    if len(data[data['z_score'].notnull()])>0:\n",
    "        user_id=f.split('/')[-1].split('.')[0]\n",
    "        lista.append(user_id)\n",
    "        list1=list(data[data['z_score'].notnull()]['z_score'].values)\n",
    "        a=numpy.array(list1)\n",
    "        median=numpy.median(a)\n",
    "        listb.append(median)\n",
    "        pertentile_10=numpy.percentile(a,10)\n",
    "        listc.append(pertentile_10)\n",
    "df=pd.DataFrame([lista,listb,listc]).T\n",
    "df.columns=['user_id','median','pertentile_10']\n",
    "df.to_csv('./siteexample1/location/zscore_category.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add category\n",
    "\n",
    "# df=pd.read_csv('./siteexample1/location/zscore_category.csv',index_col=0)\n",
    "# df=df[~df.isin([numpy.nan, numpy.inf, -numpy.inf]).any(1)]\n",
    "\n",
    "# high_low=df[(df['median']>df['median'].median())&(df['pertentile_10']>0)].index\n",
    "# df.ix[high_low,'category']='high_low'\n",
    "\n",
    "\n",
    "# low_low=df[(df['median']<=df['median'].median())&(df['pertentile_10']>0)].index\n",
    "# df.ix[low_low,'category']='low_low'\n",
    "\n",
    "# low_high=df[(df['median']<=df['median'].median())&(df['pertentile_10']<=0)].index\n",
    "# df.ix[low_high,'category']='low_high'\n",
    "\n",
    "# high_high=df[(df['median']>df['median'].median())&(df['pertentile_10']<=0)].index\n",
    "# df.ix[high_high,'category']='high_high'\n",
    "\n",
    "# df=df[['user_id','median','pertentile_10','category']]\n",
    "# df.to_csv('./siteexample1/location/zscore_category.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
